import streamlit as st
import sys
from pathlib import Path
import time

# í”„ë¡œì íŠ¸ ê²½ë¡œ ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from chains.qa_chain_with_metrics import get_qa_chain_with_metrics
from vectorstore.retriever import get_retriever
from evaluation.judge import LLMJudge
from evaluation.store import EvaluationStore

# Streamlit í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ë³´í—˜ ì•½ê´€ Q&A ì±—ë´‡",
    page_icon="ğŸ ",
    layout="wide",
    initial_sidebar_state="expanded",
)

# ì»¤ìŠ¤í…€ CSS
st.markdown("""
<style>
    .main-header {
        text-align: center;
        color: #1f77b4;
        margin-bottom: 2rem;
    }
    .answer-box {
        background-color: #f0f2f6;
        padding: 1.5rem;
        border-radius: 0.5rem;
        border-left: 5px solid #1f77b4;
        margin-top: 1rem;
        margin-bottom: 1rem;
    }
    .source-box {
        background-color: #fff9e6;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 5px solid #ffc107;
        margin-top: 1rem;
    }
    .error-box {
        background-color: #ffe6e6;
        padding: 1.5rem;
        border-radius: 0.5rem;
        border-left: 5px solid #ff6b6b;
        margin-top: 1rem;
    }
    .warning-box {
        background-color: #fff3cd;
        padding: 1.5rem;
        border-radius: 0.5rem;
        border-left: 5px solid #ffc107;
        margin-top: 1rem;
    }
    .info-box {
        background-color: #e7f3ff;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 5px solid #2196F3;
        margin-top: 1rem;
        margin-bottom: 1rem;
    }
    .metrics-box {
        background-color: #f0f8f0;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 5px solid #4CAF50;
        margin-top: 1rem;
    }
    .score-box {
        background-color: #fff5f5;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 5px solid #e91e63;
        margin-top: 1rem;
    }
</style>
""", unsafe_allow_html=True)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "qa_chain" not in st.session_state:
    st.session_state.qa_chain = None
    st.session_state.conversation_history = []
    st.session_state.qdrant_ready = False
    st.session_state.init_attempted = False
    st.session_state.enable_evaluation = True  # í‰ê°€ ëª¨ë“œ ê¸°ë³¸ê°’
    st.session_state.evaluation_store = EvaluationStore()
    st.session_state.judge = LLMJudge()
    # ìµœê·¼ ë‹µë³€ ìœ ì§€ìš©
    st.session_state.current_result = None
    st.session_state.current_question = None
    # ì‚¬ìš©ì ì²´ê° ì‹œê°„ ì¸¡ì •ìš©
    st.session_state.question_start_time = None
    st.session_state.last_processed_question = None
    # í‰ê°€ ê²°ê³¼ë¥¼ í˜„ì¬ ì§ˆë¬¸ê³¼ ë§¤í•‘
    st.session_state.current_judge_scores = None
    st.session_state.evaluated_question = None

# í—¤ë”
st.markdown('<h1 class="main-header">ğŸ  ë³´í—˜ ì•½ê´€ Q&A ì±—ë´‡</h1>', unsafe_allow_html=True)
st.markdown("""
<div style="text-align: center; color: #666; margin-bottom: 1rem;">
    <p style="font-size: 1.1rem; font-weight: 500; margin-bottom: 0.5rem;">Upstage Solar ëª¨ë¸ ê¸°ë°˜ì˜ ì§€ëŠ¥í˜• ë³´í—˜ ìƒë‹´ ì‹œìŠ¤í…œ</p>
    <p style="margin-bottom: 1rem;">ì •í™•í•œ ì•½ê´€ ì¡°í•­ì„ ê·¼ê±°ë¡œ ë‹µë³€í•´ë“œë¦½ë‹ˆë‹¤</p>
</div>
""", unsafe_allow_html=True)

# ê¸°ëŠ¥ ë° ê¸°ìˆ  ì„¤ëª… (ì ‘ê¸° ê°€ëŠ¥)
with st.expander("â„¹ï¸ ì‹œìŠ¤í…œ ì•ˆë‚´", expanded=False):
    st.markdown("""
    ### ğŸ’¡ ê¸°ëŠ¥
    
    ë³¸ ì‹œìŠ¤í…œì€ **RAG(Retrieval-Augmented Generation)** ê¸°ìˆ ì„ í™œìš©í•˜ì—¬ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë¶„ì„í•˜ê³ , 
    8ë§Œì—¬ ê°œì˜ ë³´í—˜ ì•½ê´€ ë¬¸ì„œ ì¤‘ì—ì„œ ê´€ë ¨ ì¡°í•­ì„ ìë™ìœ¼ë¡œ ê²€ìƒ‰í•©ë‹ˆë‹¤.
    
    - ğŸ“‹ **ë³´í—˜ìœ í˜• ìë™ ë¶„ë¥˜**: ì§ˆë¬¸ ë‚´ìš©ì„ ë¶„ì„í•˜ì—¬ 7ê°€ì§€ ë³´í—˜ìœ í˜• ì¤‘ ì ì ˆí•œ ìœ í˜•ì„ ìë™ìœ¼ë¡œ ë¶„ë¥˜
    - ğŸ” **í•„í„°ë§ ê²€ìƒ‰**: ë¶„ë¥˜ëœ ë³´í—˜ìœ í˜•ìœ¼ë¡œ ê´€ë ¨ ë¬¸ì„œë§Œ ì„ ë³„í•˜ì—¬ ê²€ìƒ‰ ì •í™•ë„ í–¥ìƒ
    - ğŸ“š **ê³„ì¸µì  ì¡°í•­ ì°¸ì¡°**: ì•½ê´€ì˜ level_1~level_4 êµ¬ì¡°ë¥¼ í™œìš©í•˜ì—¬ ì •í™•í•œ ì¡°í•­ ì •ë³´ ì œê³µ
    - ğŸ¤– **AI ê¸°ë°˜ ë‹µë³€ ìƒì„±**: ê²€ìƒ‰ëœ ì•½ê´€ ì¡°í•­ì„ ê·¼ê±°ë¡œ LLMì´ êµ¬ì¡°í™”ëœ ë‹µë³€ ìƒì„±
    
    âš ï¸ **ì¤‘ìš” ì•ˆë‚´**
    - ë³¸ ì‹œìŠ¤í…œì€ ì•½ê´€ìƒ ë³´ì¥ ê°€ëŠ¥ì„±ì„ **ì°¸ê³ ìš©**ìœ¼ë¡œ ì œê³µí•©ë‹ˆë‹¤
    - ì‹¤ì œ ë³´í—˜ê¸ˆ ì§€ê¸‰ ì—¬ë¶€ëŠ” ë³´í—˜ì‚¬ ì‹¬ì‚¬ ë° ê°œë³„ ì‚¬ì•ˆì— ë”°ë¼ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤
    - ì™„ë²½í•œ ë³´ì¥ ì—¬ë¶€ë¥¼ íŒë‹¨í•˜ì§€ ì•Šìœ¼ë©°, ì•½ê´€ ì¡°í•­ì„ ê·¼ê±°ë¡œ í•œ ì •ë³´ ì œê³µì— ê·¸ì¹©ë‹ˆë‹¤
    
    ---
    
    ### âš¡ ê¸°ìˆ  ìŠ¤íƒ
    
    **í•µì‹¬ ê¸°ìˆ **
    - **LangChain**: RAG íŒŒì´í”„ë¼ì¸ êµ¬ì¶• ë° ì²´ì¸ ê´€ë¦¬
    - **Upstage Solar LLM**: í•œêµ­ì–´ ìµœì í™”ëœ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸
    - **Qdrant Vector DB**: ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰ ë° ë©”íƒ€ë°ì´í„° í•„í„°ë§
    - **Sentence Transformers**: ë‹¤êµ­ì–´ ì„ë² ë”© ëª¨ë¸
    
    **ê²€ìƒ‰ ë°©ì‹**
    - **í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰**: ë³´í—˜ìœ í˜• í•„í„°ë§ + ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰
    - **Fallback ë©”ì»¤ë‹ˆì¦˜**: í•„í„° ê²€ìƒ‰ ì‹¤íŒ¨ ì‹œ ì „ì²´ ê²€ìƒ‰ìœ¼ë¡œ ìë™ ì „í™˜
    - **Top-K ê²€ìƒ‰**: ìœ ì‚¬ë„ ê¸°ë°˜ ìƒìœ„ 20ê°œ ë¬¸ì„œ ê²€ìƒ‰
    
    **í’ˆì§ˆ ë³´ì¥**
    - **LLM-as-a-Judge**: ë‹µë³€ í’ˆì§ˆì„ ë‹¤ì°¨ì›ìœ¼ë¡œ ìë™ í‰ê°€
    - **ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§**: ì‘ë‹µ ì‹œê°„, í† í° ì‚¬ìš©ëŸ‰ ë“± ì‹¤ì‹œê°„ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
    """)

# ì‚¬ì´ë“œë°”
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")
    st.markdown("---")
    
    st.subheader("ğŸ“Š ëŒ€í™” í†µê³„")
    st.metric("ì§ˆë¬¸ ìˆ˜", len(st.session_state.conversation_history))
    
    # í‰ê°€ ëª¨ë“œ í† ê¸€
    st.markdown("---")
    st.subheader("ğŸ”¬ í‰ê°€ ì„¤ì •")
    st.session_state.enable_evaluation = st.checkbox(
        "ë©”íŠ¸ë¦­ ìˆ˜ì§‘ í™œì„±í™”",
        value=st.session_state.enable_evaluation,
        help="ì„±ëŠ¥ ë©”íŠ¸ë¦­ì„ ìˆ˜ì§‘í•©ë‹ˆë‹¤ (ì‘ë‹µ ì‹œê°„, í† í° ì‚¬ìš©ëŸ‰ ë“±)"
    )
    
    # ìë™ í‰ê°€ ì˜µì…˜ (ê¸°ë³¸ê°’: OFF)
    if "auto_evaluate" not in st.session_state:
        st.session_state.auto_evaluate = False
    
    st.session_state.auto_evaluate = st.checkbox(
        "ìë™ í‰ê°€ (ì¶”ê°€ ë¹„ìš© ë°œìƒ)",
        value=st.session_state.auto_evaluate,
        help="ë‹µë³€ ì‹œ ìë™ìœ¼ë¡œ í’ˆì§ˆ í‰ê°€ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤. OFFë©´ ìˆ˜ë™ ë²„íŠ¼ìœ¼ë¡œë§Œ í‰ê°€ ê°€ëŠ¥",
        disabled=not st.session_state.enable_evaluation
    )
    
    st.markdown("---")
    
    if st.button("ğŸ”„ ëŒ€í™” ì´ˆê¸°í™”", use_container_width=True):
        st.session_state.conversation_history = []
        st.rerun()
    
    st.markdown("---")
    
    # ì„±ëŠ¥ ë©”íŠ¸ë¦­ (ìµœê·¼ ë‹µë³€)
    if st.session_state.enable_evaluation and st.session_state.get("last_metrics"):
        st.subheader("âš¡ ì„±ëŠ¥ ë©”íŠ¸ë¦­")
        metrics = st.session_state.last_metrics
        
        # ì‚¬ìš©ì ì²´ê° ì‹œê°„ ìš°ì„  í‘œì‹œ (ìˆìœ¼ë©´), ì—†ìœ¼ë©´ total_time
        user_perceived_time = metrics.get('user_perceived_time')
        if user_perceived_time:
            response_time = user_perceived_time
            response_time_label = "ì‘ë‹µ ì‹œê°„ (ì²´ê°)"
        else:
            response_time = metrics.get('total_time', 0)
            response_time_label = "ì‘ë‹µ ì‹œê°„"
        
        col1, col2 = st.columns(2)
        with col1:
            st.metric(response_time_label, f"{response_time:.2f}ì´ˆ")
            st.caption(f"ê²€ìƒ‰: {metrics.get('retrieval_time', 0):.2f}ì´ˆ | ìƒì„±: {metrics.get('generation_time', 0):.2f}ì´ˆ")
        with col2:
            st.metric("í† í° ì‚¬ìš©", f"{metrics.get('total_tokens', 0):,}")
            st.caption(f"ê²€ìƒ‰ ë¬¸ì„œ: {metrics.get('retrieved_docs_count', 0)}ê°œ")
        
        if metrics.get('fallback_activated'):
            st.warning("âš ï¸ í•„í„° ì‹¤íŒ¨ â†’ ì „ì²´ ê²€ìƒ‰")
        
        st.markdown("---")
    
    # ë‹µë³€ í’ˆì§ˆ í‰ê°€
    if st.session_state.enable_evaluation:
        st.subheader("ğŸ¯ ë‹µë³€ í’ˆì§ˆ í‰ê°€")
        
        # í‰ê°€ ì‹¤í–‰ í•¨ìˆ˜
        def run_evaluation():
            """í‰ê°€ ì‹¤í–‰ í—¬í¼ í•¨ìˆ˜"""
            if not st.session_state.get("last_question"):
                return False
            
            try:
                judge_scores = st.session_state.judge.evaluate_answer(
                    question=st.session_state.last_question,
                    answer=st.session_state.last_answer,
                    context=st.session_state.last_context,
                    docs=st.session_state.last_docs
                )
                
                # ì„¸ì…˜ì— ì €ì¥ (í˜„ì¬ ì§ˆë¬¸ê³¼ í•¨ê»˜)
                st.session_state.current_judge_scores = judge_scores
                st.session_state.last_judge_scores = judge_scores
                st.session_state.evaluated_question = st.session_state.last_question
                
                # íˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸
                if st.session_state.conversation_history:
                    st.session_state.conversation_history[-1]["judge_scores"] = judge_scores
                
                # ê²°ê³¼ ì €ì¥
                st.session_state.evaluation_store.save_evaluation(
                    question=st.session_state.last_question,
                    answer=st.session_state.last_answer,
                    metrics=st.session_state.get("last_metrics", {}),
                    judge_scores=judge_scores,
                    metadata={
                        "insurance_type": st.session_state.last_insurance_type,
                        "docs_count": len(st.session_state.last_docs),
                    }
                )
                return True
            except Exception as e:
                st.error(f"âŒ í‰ê°€ ì‹¤íŒ¨: {str(e)}")
                return False
        
        # í‰ê°€ ë²„íŠ¼ (ìˆ˜ë™ í‰ê°€) - í˜„ì¬ ì§ˆë¬¸ì´ ìˆìœ¼ë©´ í•­ìƒ í‘œì‹œ (ì¬í‰ê°€ ê°€ëŠ¥)
        current_question = st.session_state.get("last_question")
        
        # í˜„ì¬ ì§ˆë¬¸ì´ ìˆìœ¼ë©´ í•­ìƒ ë²„íŠ¼ í‘œì‹œ (í‰ê°€ ì™„ë£Œ ì—¬ë¶€ì™€ ê´€ê³„ì—†ì´)
        if current_question is not None:
            # ë²„íŠ¼ í…ìŠ¤íŠ¸: í‰ê°€ ì™„ë£Œ ì—¬ë¶€ì— ë”°ë¼ ë‹¤ë¥´ê²Œ í‘œì‹œ
            evaluated_question = st.session_state.get("evaluated_question")
            has_evaluation = (
                st.session_state.get("current_judge_scores") is not None 
                and evaluated_question == current_question
            )
            
            button_text = "ğŸ”„ ë‹µë³€ ì¬í‰ê°€í•˜ê¸°" if has_evaluation else "ğŸ”¬ í˜„ì¬ ë‹µë³€ í‰ê°€í•˜ê¸°"
            
            if st.button(button_text, use_container_width=True):
                with st.spinner("í‰ê°€ ì¤‘..."):
                    if run_evaluation():
                        st.rerun()
        
        # í‰ê°€ ê²°ê³¼ í‘œì‹œ (í˜„ì¬ ì§ˆë¬¸ê³¼ ì¼ì¹˜í•˜ëŠ” í‰ê°€ë§Œ í‘œì‹œ)
        current_scores = st.session_state.get("current_judge_scores")
        evaluated_q = st.session_state.get("evaluated_question")
        last_q = st.session_state.get("last_question")
        
        if (current_scores is not None 
            and evaluated_q is not None 
            and last_q is not None
            and evaluated_q == last_q):
            scores = current_scores
            
            col1, col2, col3, col4, col5 = st.columns(5)
            with col1:
                st.metric("ê´€ë ¨ì„±", f"{scores.get('relevance', 0)}/5")
            with col2:
                st.metric("ì •í™•ë„", f"{scores.get('accuracy', 0)}/5")
            with col3:
                st.metric("ìœ ìš©ì„±", f"{scores.get('helpfulness', 0)}/5")
            with col4:
                st.metric("ì™„ì „ì„±", f"{scores.get('completeness', 0)}/5")
            with col5:
                st.metric("ê·¼ê±° ì¶©ì‹¤ë„", f"{scores.get('groundedness', 0)}/5")
            
            avg_score = scores.get('average_score', 0)
            st.progress(avg_score / 5.0)
            st.caption(f"í‰ê·  ì ìˆ˜: {avg_score:.2f}/5.0")
            
            if scores.get('explanation'):
                with st.expander("ğŸ“ í‰ê°€ ì„¤ëª…"):
                    st.write(scores['explanation'])
        
        st.markdown("---")
    
    # í‰ê°€ í†µê³„
    if st.session_state.enable_evaluation:
        st.subheader("ğŸ“ˆ í‰ê°€ í†µê³„")
        
        stats = st.session_state.evaluation_store.get_statistics()
        if stats["total_evaluations"] > 0:
            col1, col2 = st.columns(2)
            with col1:
                st.metric("ì´ í‰ê°€ ìˆ˜", stats["total_evaluations"])
                st.metric("í‰ê·  ì‘ë‹µ ì‹œê°„", f"{stats['avg_response_time']:.2f}ì´ˆ")
                st.metric("í‰ê·  í† í° ì‚¬ìš©", f"{stats['avg_token_usage']:.0f}")
            with col2:
                if stats['avg_relevance_score'] > 0:
                    st.metric("í‰ê·  ê´€ë ¨ì„±", f"{stats['avg_relevance_score']:.2f}/5.0")
                st.metric("í•„í„° ì„±ê³µë¥ ", f"{stats['filter_success_rate']*100:.1f}%")
                st.metric("Fallback ë¹„ìœ¨", f"{stats['fallback_rate']*100:.1f}%")
            
            if st.button("ğŸ“¥ í‰ê°€ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ", use_container_width=True):
                export_file = st.session_state.evaluation_store.export_to_json()
                st.success(f"âœ… ì €ì¥ ì™„ë£Œ: {export_file.name}")
        else:
            st.info("ì•„ì§ í‰ê°€ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        st.markdown("---")
    
    st.markdown("---")
    
    st.subheader("ğŸ’¡ ì‚¬ìš© íŒ")
    st.info("""
    **ì§ˆë¬¸ ì˜ˆì‹œ:**
    - "ëŒ€ì¤‘êµí†µ ì´ìš© ì¤‘ ë‹¤ì³¤ëŠ”ë° ë³´í—˜ ë³´ì¥ë°›ì„ ìˆ˜ ìˆë‚˜ìš”?"
    - "ìŒì£¼ìš´ì „ ì‚¬ê³  ì‹œ ë³´í—˜ ì ìš© ê°€ëŠ¥í•œê°€ìš”?"
    - "ë‡Œì¶œí˜ˆë¡œ ì§„ë‹¨ í™•ì •ë˜ë©´ ì–´ë–¤ ë³´í—˜ê¸ˆì´ ì§€ê¸‰ë˜ë‚˜ìš”? ì²­êµ¬ ìš”ê±´ì€ ë¬´ì—‡ì¸ê°€ìš”?"
    """)
    
    st.markdown("---")
    
    st.subheader("ğŸ”— ë³´í—˜ ìƒí’ˆ")
    insurance_types = [
        "ìƒí•´ë³´í—˜",
        "ì†í•´ë³´í—˜",
        "ì—°ê¸ˆë³´í—˜",
        "ìë™ì°¨ë³´í—˜",
        "ì§ˆë³‘ë³´í—˜",
        "ì±…ì„ë³´í—˜",
        "í™”ì¬ë³´í—˜",
    ]
    for ins in insurance_types:
        st.caption(f"âœ“ {ins}")

# ë©”ì¸ ì½˜í…ì¸ 
col1, col2 = st.columns([2, 1], gap="large")

with col1:
    st.subheader("ğŸ’¬ ì§ˆë¬¸ ì…ë ¥")
    
    # Qdrant ì—°ê²° ìƒíƒœ í™•ì¸
    if not st.session_state.init_attempted:
        st.session_state.init_attempted = True
        with st.spinner("ğŸ”„ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘..."):
            try:
                # Qdrant ì—°ê²° í…ŒìŠ¤íŠ¸
                retriever = get_retriever()
                st.session_state.qdrant_ready = True
                st.session_state.qa_chain = get_qa_chain_with_metrics(enable_metrics=True)
            except ConnectionRefusedError as e:
                st.session_state.qdrant_ready = False
                st.markdown(f"""
<div class="error-box">
<h3>âŒ Qdrant ì„œë²„ ì—°ê²° ì‹¤íŒ¨</h3>
<p><b>ì˜¤ë¥˜:</b> Qdrant ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.</p>
<p><b>í•´ê²° ë°©ë²•:</b></p>
<ol>
<li><b>Docker ì‹œì‘:</b>
<pre>docker run -p 6333:6333 qdrant/qdrant</pre>
ë˜ëŠ” Docker Desktop ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ì‹¤í–‰í•˜ì„¸ìš”.</li>
<li>ìœ„ ëª…ë ¹ í›„ ì´ í˜ì´ì§€ë¥¼ ìƒˆë¡œê³ ì¹¨í•˜ì„¸ìš” (F5)</li>
<li>ê³„ì†í•´ì„œ ì˜¤ë¥˜ê°€ ë°œìƒí•˜ë©´ í„°ë¯¸ë„ì—ì„œ ë‹¤ìŒì„ í™•ì¸í•˜ì„¸ìš”:
<pre>docker ps</pre></li>
</ol>
<p><b>ìƒì„¸ ì˜¤ë¥˜:</b> {str(e)}</p>
</div>
""", unsafe_allow_html=True)
            except Exception as e:
                st.session_state.qdrant_ready = False
                st.markdown(f"""
<div class="error-box">
<h3>âŒ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì˜¤ë¥˜</h3>
<p><b>ì˜¤ë¥˜ ë©”ì‹œì§€:</b> {str(e)}</p>
<p><b>í•´ê²° ë°©ë²•:</b></p>
<ol>
<li>Dockerê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•˜ì„¸ìš”: <code>docker ps</code></li>
<li>Qdrant ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•˜ì„¸ìš”: <code>docker run -p 6333:6333 qdrant/qdrant</code></li>
<li>.env íŒŒì¼ì˜ UPSTAGE_API_KEYê°€ ì„¤ì •ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”</li>
<li>í˜ì´ì§€ë¥¼ ìƒˆë¡œê³ ì¹¨í•˜ì„¸ìš” (F5)</li>
</ol>
</div>
""", unsafe_allow_html=True)
    
    # Qdrant ì¤€ë¹„ë¨ - ì§ˆë¬¸ ì…ë ¥ í—ˆìš©
    if st.session_state.qdrant_ready and st.session_state.qa_chain is not None:
        question = st.text_input(
            "ë³´í—˜ì— ëŒ€í•´ ê¶ê¸ˆí•œ ì ì„ ë¬¼ì–´ë³´ì„¸ìš”:",
            placeholder="ì˜ˆ: ëŒ€ì¤‘êµí†µ ì´ìš© ì¤‘ ë‹¤ì³¤ëŠ”ë° ë³´í—˜ ë³´ì¥ë°›ì„ ìˆ˜ ìˆë‚˜ìš”?",
            label_visibility="collapsed"
        )
        
        # ì§ˆë¬¸ ì²˜ë¦¬
        if question:
            import time
            
            # ìƒˆ ì§ˆë¬¸ì¸ì§€ í™•ì¸ (ì§ˆë¬¸ì´ ë³€ê²½ë˜ì—ˆê±°ë‚˜ ì²˜ìŒ ì§ˆë¬¸)
            is_new_question = (
                st.session_state.last_processed_question != question or
                st.session_state.last_processed_question is None
            )
            
            with st.spinner("ğŸ” ì•½ê´€ì„ ê²€ìƒ‰í•˜ê³  ë‹µë³€ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
                # ìŠ¤í”¼ë„ˆ ë¸”ë¡ ì‹œì‘ ì§í›„ ì‹œê°„ ì¸¡ì • (ì‹¤ì œ ì‚¬ìš©ìê°€ ë³´ê¸° ì‹œì‘í•˜ëŠ” ì‹œì )
                user_start_time = time.time()
                
                try:
                    # ë‹µë³€ ìƒì„± (ë©”íŠ¸ë¦­ í¬í•¨)
                    result = st.session_state.qa_chain.invoke({
                        "question": question,
                        "enable_metrics": st.session_state.enable_evaluation
                    })
                    
                    # ì‘ì—… ì™„ë£Œ ì§í›„ ì‹œê°„ ì¸¡ì • (ë‹µë³€ ìƒì„± ì™„ë£Œ ì‹œì )
                    user_end_time = time.time()
                    user_perceived_time = user_end_time - user_start_time
                    
                    # ì‚¬ìš©ì ì²´ê° ì‹œê°„ì„ ë©”íŠ¸ë¦­ì— ì¶”ê°€
                    if result.get("metrics"):
                        result["metrics"]["user_perceived_time"] = user_perceived_time
                    
                    # ìƒˆ ì§ˆë¬¸ ì²˜ë¦¬ ì™„ë£Œ í‘œì‹œ
                    if is_new_question:
                        st.session_state.last_processed_question = question
                    
                    # ëŒ€í™” íˆìŠ¤í† ë¦¬ ì¶”ê°€
                    st.session_state.conversation_history.append({
                        "question": question,
                        "answer": result.get("answer", ""),
                        "metrics": result.get("metrics"),
                        "judge_scores": None,  # ë‚˜ì¤‘ì— ì±„ì›Œì§
                    })
                    
                    # í˜„ì¬ ë‹µë³€ì„ ì„¸ì…˜ì— ì €ì¥ (rerun í›„ì—ë„ ìœ ì§€)
                    st.session_state.current_result = result
                    st.session_state.current_question = question
                    
                    # ë©”íŠ¸ë¦­ì„ ì„¸ì…˜ì— ì €ì¥ (ì‚¬ì´ë“œë°”ì—ì„œ í‘œì‹œìš©)
                    if result.get("metrics") and st.session_state.enable_evaluation:
                        st.session_state.last_metrics = result["metrics"]
                    else:
                        st.session_state.last_metrics = None
                    
                    # í‰ê°€ìš© ë°ì´í„° ì €ì¥
                    st.session_state.last_question = question
                    st.session_state.last_answer = result.get("answer", "")
                    st.session_state.last_context = result.get("context", "")
                    st.session_state.last_docs = result.get("docs", [])
                    st.session_state.last_insurance_type = result.get("insurance_type")
                    
                    # í‰ê°€ ê²°ê³¼ ì´ˆê¸°í™” (ìƒˆ ë‹µë³€ ìƒì„± ì‹œ í˜„ì¬ ì§ˆë¬¸ê³¼ ë¶ˆì¼ì¹˜í•˜ëŠ” í‰ê°€ ì œê±°)
                    # í˜„ì¬ ì§ˆë¬¸ê³¼ ì¼ì¹˜í•˜ì§€ ì•Šìœ¼ë©´ í‰ê°€ ê²°ê³¼ë¥¼ Noneìœ¼ë¡œ ì„¤ì •
                    evaluated_q = st.session_state.get("evaluated_question")
                    if evaluated_q is None or evaluated_q != question:
                        st.session_state.current_judge_scores = None
                        st.session_state.last_judge_scores = None
                    
                    # ìë™ í‰ê°€ ì‹¤í–‰ (ì˜µì…˜ì´ ì¼œì ¸ ìˆëŠ” ê²½ìš°, ìƒˆ ì§ˆë¬¸ì´ë©´ ë°”ë¡œ ì‹¤í–‰)
                    if (st.session_state.enable_evaluation 
                        and st.session_state.get("auto_evaluate", False)
                        and is_new_question):
                        st.session_state.pending_evaluation = True
                    
                except Exception as e:
                    st.error(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                    import traceback
                    st.code(traceback.format_exc())
                    result = None
        
        # ë‹µë³€ í‘œì‹œ (ìƒˆ ë‹µë³€ ë˜ëŠ” ì €ì¥ëœ ë‹µë³€)
        current_result = st.session_state.get("current_result")
        if current_result:
            # ë‹µë³€ í‘œì‹œ
            st.markdown('<div class="answer-box">', unsafe_allow_html=True)
            st.markdown("### ğŸ“‹ ë‹µë³€")
            st.write(current_result.get("answer", "ì•½ê´€ì—ì„œ ëª…í™•í•œ ê·¼ê±°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"))
            st.markdown('</div>', unsafe_allow_html=True)
            
            # ë³´í—˜ìœ í˜•, ì ìš© ì¡°í•­ í‘œì‹œ
            st.markdown('<div class="info-box">', unsafe_allow_html=True)
            insurance_type = current_result.get("insurance_type")
            if insurance_type:
                st.markdown(f"**ë³´í—˜ìœ í˜•:** {insurance_type}")

            levels = ["level_1", "level_2", "level_3", "level_4"]
            level_texts = [f"- {current_result.get(l, '')}" for l in levels if current_result.get(l)]
            if level_texts:
                st.markdown("**ì ìš© ì¡°í•­:**")
                st.markdown("\n".join(level_texts))
            st.markdown('</div>', unsafe_allow_html=True)

            # ì°¸ê³  ì•½ê´€ í‘œì‹œ
            docs = current_result.get("docs", [])
            if docs:
                st.markdown('<div class="source-box">', unsafe_allow_html=True)
                st.markdown("### ğŸ“š ì°¸ê³  ì•½ê´€")
                
                for i, doc in enumerate(docs[:2], 1):
                    source_path = doc.metadata.get("source", "")
                    source_name = Path(source_path).name if source_path else "Unknown"
                    with st.expander(f"ğŸ“„ {source_name} - ë¬¸ì„œ {i}"):
                        st.write(doc.page_content)
                
                st.markdown('</div>', unsafe_allow_html=True)
        
        # ìë™ í‰ê°€ ì‹¤í–‰ (ë‹µë³€ í‘œì‹œ í›„)
        if (st.session_state.enable_evaluation 
            and st.session_state.get("auto_evaluate", False)
            and st.session_state.get("pending_evaluation", False)
            and st.session_state.get("last_question")
            and st.session_state.evaluated_question != st.session_state.last_question):
            
            st.session_state.pending_evaluation = False  # í”Œë˜ê·¸ ì œê±°
            
            with st.spinner("ğŸ”¬ ë‹µë³€ í’ˆì§ˆ í‰ê°€ ì¤‘..."):
                try:
                    judge_scores = st.session_state.judge.evaluate_answer(
                        question=st.session_state.last_question,
                        answer=st.session_state.last_answer,
                        context=st.session_state.last_context,
                        docs=st.session_state.last_docs
                    )
                    
                    # ì„¸ì…˜ì— ì €ì¥ (í˜„ì¬ ì§ˆë¬¸ê³¼ í•¨ê»˜)
                    st.session_state.current_judge_scores = judge_scores
                    st.session_state.last_judge_scores = judge_scores
                    st.session_state.evaluated_question = st.session_state.last_question
                    
                    # íˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸
                    if st.session_state.conversation_history:
                        st.session_state.conversation_history[-1]["judge_scores"] = judge_scores
                    
                    # ê²°ê³¼ ì €ì¥
                    st.session_state.evaluation_store.save_evaluation(
                        question=st.session_state.last_question,
                        answer=st.session_state.last_answer,
                        metrics=st.session_state.get("last_metrics", {}),
                        judge_scores=judge_scores,
                        metadata={
                            "insurance_type": st.session_state.last_insurance_type,
                            "docs_count": len(st.session_state.last_docs),
                        }
                    )
                    st.rerun()
                    
                except Exception as e:
                    st.error(f"âŒ í‰ê°€ ì‹¤íŒ¨: {str(e)}")
                    st.session_state.pending_evaluation = False
    
    elif not st.session_state.qdrant_ready:
        st.markdown("""
<div class="warning-box">
<h3>âš ï¸ ì‹œìŠ¤í…œ ì¤€ë¹„ ì¤‘</h3>
<p>Qdrant ì„œë²„ë¥¼ ì‹¤í–‰í•œ í›„ í˜ì´ì§€ë¥¼ ìƒˆë¡œê³ ì¹¨í•˜ì„¸ìš” (F5)</p>
<p><b>í„°ë¯¸ë„ì—ì„œ ë‹¤ìŒì„ ì‹¤í–‰í•˜ì„¸ìš”:</b></p>
<pre>docker run -p 6333:6333 qdrant/qdrant</pre>
</div>
""", unsafe_allow_html=True)

# ëŒ€í™” íˆìŠ¤í† ë¦¬ í‘œì‹œ
with col2:
    st.subheader("ğŸ“ ëŒ€í™” íˆìŠ¤í† ë¦¬")
    
    if st.session_state.conversation_history:
        for i, conv in enumerate(reversed(st.session_state.conversation_history), 1):
            idx = len(st.session_state.conversation_history) - i + 1
            with st.expander(f"ì§ˆë¬¸ {idx}"):
                st.markdown("**Q:** " + conv["question"])
                st.markdown("---")
                answer_preview = conv["answer"][:200] + "..." if len(conv["answer"]) > 200 else conv["answer"]
                st.markdown("**A:** " + answer_preview)
                
                # ê°„ë‹¨í•œ ìš”ì•½ë§Œ í‘œì‹œ (ìì„¸í•œ ë‚´ìš©ì€ expander ë‚´ë¶€ì—ì„œ)
                if conv.get("metrics"):
                    m = conv["metrics"]
                    st.caption(f"â±ï¸ {m.get('total_time', 0):.1f}ì´ˆ")
                
                if conv.get("judge_scores"):
                    js = conv["judge_scores"]
                    avg = js.get('average_score', 0)
                    st.caption(f"â­ {avg:.1f}/5.0")
    else:
        st.info("ì•„ì§ ì§ˆë¬¸ì´ ì—†ìŠµë‹ˆë‹¤. ì™¼ìª½ì—ì„œ ì§ˆë¬¸ì„ ì…ë ¥í•´ë³´ì„¸ìš”! ğŸ‘ˆ")

# í•˜ë‹¨ ì •ë³´
st.markdown("---")
st.markdown("""
<div style="text-align: center; color: #999; font-size: 0.85rem; padding: 1rem 0;">
    <p style="margin-bottom: 0.5rem;">ğŸ” <b>ë³´ì•ˆ:</b> ëª¨ë“  ë°ì´í„°ëŠ” ë¡œì»¬ì—ì„œ ì²˜ë¦¬ë˜ë©°, ì™¸ë¶€ë¡œ ì „ì†¡ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.</p>
    <p style="margin-bottom: 0.5rem;">âš¡ <b>ê¸°ìˆ :</b> LangChain + Upstage Solar + Qdrant Vector DB | RAG ê¸°ë°˜ ê²€ìƒ‰ì„ í†µí•´ ê´€ë ¨ ì•½ê´€ ì¡°í•­ì„ ì°¸ì¡°í•˜ì—¬ ë‹µë³€ ìƒì„±</p>
    <p style="margin-bottom: 0.5rem;">ğŸ“Š <b>í‰ê°€:</b> LLM-as-a-Judge ê¸°ë°˜ ìë™ í’ˆì§ˆ í‰ê°€ ì‹œìŠ¤í…œ</p>
    <p style="margin-top: 0.5rem; padding-top: 0.5rem; border-top: 1px solid #ddd;">
        ğŸ“œ <b>ë²„ì „:</b> v2.1.0 (í‰ê°€ ê¸°ëŠ¥ ì‚¬ì´ë“œë°” í†µí•©) | ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸: 2026ë…„ 1ì›” 15ì¼
    </p>
</div>
""", unsafe_allow_html=True)
